xgb_Wd_sftmx_md10_x7x3_7e3
{'lr': 0.001, 'batch_size': 7000, 'N_epochs': 200, 'seed': 0}
>> Training...
  0%|          | 0/200 [00:00<?, ?it/s]/vols/cms/hw423/Week14/A_Post_trains/InferenceAware_Trainning.py:92: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  theta = torch.tensor(theta_init)
/vols/cms/hw423/Week14/A_Post_trains/InferenceAware_Trainning.py:72: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  return F.softmax(out)
  0%|          | 0/200 [00:08<?, ?it/s]
Traceback (most recent call last):
  File "/vols/cms/hw423/Week14/A_Post_trains/InferenceAware_Trainning.py", line 211, in <module>
    model, train_loss_ia, test_loss_ia = train_network(model_ia, X_train, X_test, y_train, y_test,w_train,w_test, train_hp=train_hp)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/vols/cms/hw423/Week14/A_Post_trains/InferenceAware_Trainning.py", line 166, in train_network
    raise ValueError("Loss is NaN, terminating training")
ValueError: Loss is NaN, terminating training
