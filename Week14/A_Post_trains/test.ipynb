{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced_batches(x, y,w, batch_size = None):\n",
    "    x = torch.tensor(x)\n",
    "    y = torch.tensor(y)\n",
    "    w = torch.tensor(w)\n",
    "    unique_classes = dfy.unique()\n",
    "    batches = torch.tensor([])\n",
    "    for cls in unique_classes:\n",
    "        cls_indices = dfy[dfy == cls].nonzero()\n",
    "        cls_dfx = x[cls_indices]\n",
    "        cls_dfy = y[cls_indices]\n",
    "        cls_dfw = w[cls_indices]\n",
    "        cls_data = list(zip(cls_dfx, cls_dfy, cls_dfw))\n",
    "        np.random.shuffle(cls_data)\n",
    "        cls_batches = torch.tensor([cls_data[i:i + batch_size // len(unique_classes)] for i in range(0, len(cls_data), batch_size // len(unique_classes))])\n",
    "        torch.cat([batches,cls_batches])\n",
    "    np.random.shuffle(batches)\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_train\n",
    "y = y_train\n",
    "w = w_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(np.array(x))\n",
    "y = torch.tensor(np.array(y),dtype = torch.float32)\n",
    "w = torch.tensor(np.array(w))\n",
    "batches = torch.tensor([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (1762461581.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[274], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    def get_balanced_batch(x,y,w,bathchsize)\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "batchsize=1000\n",
    "def get_balanced_batch(x,y,w,bathchsize)\n",
    "    batch = []\n",
    "    dim = y.size()[1]\n",
    "    size = y.size()[0]\n",
    "    num  = size // batchsize\n",
    "    for i in range(dim):\n",
    "        filted = x.T*y.T[i]\n",
    "        msk = (filted).mean(dim=0)!=0\n",
    "        btx = filted[:,msk.view(-1)].T\n",
    "        filted = y.T*y.T[i]\n",
    "        msk = (filted).mean(dim=0)!=0\n",
    "        bty = filted[:,msk.view(-1)].T\n",
    "        filted = w.T*y.T[i]\n",
    "        msk = filted!=0\n",
    "        btw = (filted[msk.view(-1)].T).view(-1,1)\n",
    "        bt = [btx,bty,btw]\n",
    "        batch.append(bt)\n",
    "\n",
    "    batches = []\n",
    "    for n in range(num):\n",
    "        id = n*batchsize\n",
    "        x_b=torch.tensor([])\n",
    "        y_b=torch.tensor([])\n",
    "        w_b=torch.tensor([])\n",
    "        for i in range(dim):\n",
    "            x_b= torch.cat([x_b,batch[i][0][id:id+batchsize]])\n",
    "            y_b= torch.cat([y_b,batch[i][1][id:id+batchsize]])\n",
    "            w_b= torch.cat([w_b,batch[i][2][id:id+batchsize]])\n",
    "        batches.append([x_b,y_b,w_b])\n",
    "    return batches\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "a Tensor with 7 elements cannot be converted to Scalar",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[302], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mbatchsize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: a Tensor with 7 elements cannot be converted to Scalar"
     ]
    }
   ],
   "source": [
    "(y.sum(dim=0)/y.sum()*batchsize).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7000, 7])\n",
      "torch.Size([7000, 7])\n",
      "torch.Size([7000, 7])\n",
      "torch.Size([7000, 7])\n",
      "torch.Size([7000, 7])\n",
      "torch.Size([7000, 7])\n",
      "torch.Size([7000, 7])\n",
      "torch.Size([7000, 7])\n",
      "torch.Size([7000, 7])\n",
      "torch.Size([7000, 7])\n"
     ]
    }
   ],
   "source": [
    "for BX,BY,BW in batches[:10]:\n",
    "    print(BY.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.4112e-02, 8.6659e-01, 3.6283e-02,  ..., 9.4449e-04, 3.9948e-05,\n",
       "         9.1545e-04],\n",
       "        [1.9582e-01, 1.5962e-01, 2.6510e-01,  ..., 7.2050e-04, 4.1710e-02,\n",
       "         3.3465e-01],\n",
       "        [5.5543e-02, 8.9861e-01, 4.3566e-02,  ..., 8.8505e-04, 2.7090e-05,\n",
       "         5.6236e-04],\n",
       "        ...,\n",
       "        [2.3576e-01, 5.5713e-02, 4.7241e-01,  ..., 1.0165e-03, 2.3923e-03,\n",
       "         2.2994e-01],\n",
       "        [2.9131e-02, 4.2706e-01, 4.9737e-01,  ..., 1.6510e-03, 3.5151e-04,\n",
       "         4.2112e-02],\n",
       "        [1.9602e-01, 2.3108e-01, 3.1793e-01,  ..., 1.7122e-03, 4.9433e-03,\n",
       "         2.4585e-01]], dtype=torch.float32)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0][0][0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4.8447e-02, 1.1093e-02, 4.7640e-02,  ..., 7.3550e-04,\n",
       "          4.0461e-01, 4.8260e-01],\n",
       "         [5.3815e-04, 8.7645e-04, 3.2505e-03,  ..., 2.0515e-05,\n",
       "          1.4548e-01, 8.4982e-01],\n",
       "         [5.6603e-03, 8.4991e-03, 9.2135e-03,  ..., 7.8373e-03,\n",
       "          1.2666e-01, 8.1915e-01],\n",
       "         ...,\n",
       "         [7.1522e-06, 6.5898e-06, 1.0951e-05,  ..., 9.0639e-05,\n",
       "          5.1322e-03, 9.9447e-01],\n",
       "         [1.6767e-03, 4.3159e-03, 1.2776e-02,  ..., 6.7657e-05,\n",
       "          1.8397e-02, 9.6270e-01],\n",
       "         [9.6690e-03, 1.8396e-01, 1.0170e-01,  ..., 4.4483e-04,\n",
       "          2.0049e-03, 7.0087e-01]],\n",
       "\n",
       "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 1.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 1.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 1.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 1.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 1.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 1.0000e+00]]], dtype=torch.float32)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy = torch.cat([btx,bty])\n",
    "xy.view(2,-1,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.8447e-02, 1.1093e-02, 4.7640e-02,  ..., 7.3550e-04, 4.0461e-01,\n",
       "         4.8260e-01],\n",
       "        [5.3815e-04, 8.7645e-04, 3.2505e-03,  ..., 2.0515e-05, 1.4548e-01,\n",
       "         8.4982e-01],\n",
       "        [5.6603e-03, 8.4991e-03, 9.2135e-03,  ..., 7.8373e-03, 1.2666e-01,\n",
       "         8.1915e-01],\n",
       "        ...,\n",
       "        [7.1522e-06, 6.5898e-06, 1.0951e-05,  ..., 9.0639e-05, 5.1322e-03,\n",
       "         9.9447e-01],\n",
       "        [1.6767e-03, 4.3159e-03, 1.2776e-02,  ..., 6.7657e-05, 1.8397e-02,\n",
       "         9.6270e-01],\n",
       "        [9.6690e-03, 1.8396e-01, 1.0170e-01,  ..., 4.4483e-04, 2.0049e-03,\n",
       "         7.0087e-01]], dtype=torch.float32)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "M = torch.einsum('kn,nm->knm', y.T, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls in unique_classes:\n",
    "    cls_indices = dfy[dfy == cls].nonzero()\n",
    "    cls_dfx = x[cls_indices]\n",
    "    cls_dfy = y[cls_indices]\n",
    "    cls_dfw = w[cls_indices]\n",
    "    cls_data = list(zip(cls_dfx, cls_dfy, cls_dfw))\n",
    "    np.random.shuffle(cls_data)\n",
    "    cls_batches = torch.tensor([cls_data[i:i + batch_size // len(unique_classes)] for i in range(0, len(cls_data), batch_size // len(unique_classes))])\n",
    "    torch.cat([batches,cls_batches])\n",
    "np.random.shuffle(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# filecode = 'x10x40'\n",
    "filecode = 'InfA_xgb_AJF'\n",
    "savecode = 'x14x2'\n",
    "train_hp = {\n",
    "    \"lr\":3e-5,\n",
    "    \"batch_size\":1000,\n",
    "    \"N_epochs\":400,\n",
    "    \"seed\":0,\n",
    "\n",
    "}\n",
    "\n",
    "oc = np.load(f'/vols/cms/hw423/Data/Week14/octest_{filecode}.npy')\n",
    "df = pd.DataFrame(oc)\n",
    "dfx = df\n",
    "\n",
    "label = pd.read_pickle('/vols/cms/hw423/Data/Week14/Label.pkl')\n",
    "dfy = pd.get_dummies(label)\n",
    "dfw = pd.read_pickle('/vols/cms/hw423/Data/Week14/weight.pkl')\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test, w_train, w_test = train_test_split(dfx, dfy,dfw, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# optimiser = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "X_train =X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()\n",
    "w_train = w_train.to_numpy()\n",
    "w_test = w_test.to_numpy()\n",
    "\n",
    "train_loss, test_loss = [], []\n",
    "mu_ini = torch.ones(6)\n",
    "ia_loss = lambda x,y,w,m: InfAwareLoss(x,y,w,m,mu_ini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m batch_gen \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_balanced_batches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_hp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# for batch in batch_gen:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#     batch = torch.tensor(np.array(batch)).T\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#     print(batch.size())\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#     X_tensor, y_tensor, w_tensor = batch\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[20], line 14\u001b[0m, in \u001b[0;36mcreate_balanced_batches\u001b[0;34m(dfx, dfy, dfw, batch_size)\u001b[0m\n\u001b[1;32m     13\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mshuffle(cls_data)\n\u001b[0;32m---> 14\u001b[0m cls_batches \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcls_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m:\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43munique_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcls_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43munique_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m torch\u001b[38;5;241m.\u001b[39mcat([batches,cls_batches])\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/vols/cms/hw423/env/envs/env/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3571\u001b[0m, in \u001b[0;36mInteractiveShell.run_code\u001b[0;34m(self, code_obj, result, async_)\u001b[0m\n\u001b[1;32m   3569\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m   3570\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 3571\u001b[0m         result\u001b[38;5;241m.\u001b[39merror_in_exec \u001b[38;5;241m=\u001b[39m \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   3572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshowtraceback(running_compiled_code\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   3573\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_gen = create_balanced_batches(X_train, y_train, w_train, batch_size = train_hp['batch_size'])\n",
    "# for batch in batch_gen:\n",
    "#     batch = torch.tensor(np.array(batch)).T\n",
    "#     print(batch.size())\n",
    "#     X_tensor, y_tensor, w_tensor = batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_gen\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "torch.tensor(batch_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df.sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41187      1.926653\n",
       "2794036   -0.574445\n",
       "2442116    0.632852\n",
       "2458252   -0.352543\n",
       "274446    -0.491701\n",
       "             ...   \n",
       "870664    -0.533073\n",
       "2748466   -0.164490\n",
       "1653439   -0.469135\n",
       "2130389   -0.668471\n",
       "894239     1.024001\n",
       "Name: subleadPhotonSigmaE, Length: 1000, dtype: float32"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample['subleadPhotonSigmaE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([578., 228., 106.,  51.,  19.,   8.,   4.,   3.,   2.,   1.]),\n",
       " array([-1.00466573, -0.18641947,  0.63182676,  1.450073  ,  2.26831937,\n",
       "         3.08656549,  3.90481186,  4.72305822,  5.54130411,  6.35955048,\n",
       "         7.17779684]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df_sample['subleadPhotonEn'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
